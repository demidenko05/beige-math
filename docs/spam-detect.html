<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="icon" type="image/png" href="img/favicon.png">
    <script src="js/bootstrap.bundle.min.js"></script>
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/navbar-top.css" rel="stylesheet">
  </head>
  <body>

    <nav class="navbar navbar-expand-md navbar-dark sidebar bg-dark mb-4">
      <div class="container-fluid">
        <a href="index.html" class="navbar-brand navbar-brand-img"><img src="img/logo.png"></a>
        <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button>
        <div class="collapse navbar-collapse" id="navbarCollapse">
          <ul class="navbar-nav me-auto mb-2 mb-md-0">
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" href="#" id="dropdown01" data-bs-toggle="dropdown" aria-expanded="false">Articles</a>
              <ul class="dropdown-menu" aria-labelledby="dropdown01">
                <li><a class="dropdown-item" href="svmidx.html">Understanding Support Vector Machines.</a></li>
                <li><a class="dropdown-item" href="spam-detect.html">Detecting spam in SMS unlabeled data.</a></li>
              </ul>
            </li>
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" href="#" id="dropdown01" data-bs-toggle="dropdown" aria-expanded="false">Info</a>
              <ul class="dropdown-menu" aria-labelledby="dropdown01">
                <li><a class="dropdown-item" href="license-bsmath.html">Beigesoft™ Math License</a></li>
              </ul>
            </li>
          </ul>
          <ul class="navbar-nav navbar-right">
            <li class="nav-item">
              <a class="nav-link" href="https://demidenko05.github.io/beige-acc/">Beigesoft™ main site</a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <main class="container">
    
    <div>

      <h3>Detecting spam in SMS unlabeled data.</h3>
      <p>
        Look at these 5 messages from <a href="#KAGGLE-SMS">SMS data</a>:
<pre>
"XXXMobileMovieClub: To use your credit, click the WAP link in the next txt message or click here>> http://wap. xxxmobilemovieclub.com?n=QJKGIGHJJGCBL"
Oh k...i'm watching here:)
Eh u remember how 2 spell his name... Yes i did. He v naughty make until i v wet.
Fine if thatåÕs the way u feel. ThatåÕs the way its gota b
"England v Macedonia - dont miss the goals/team news. Txt ur national team to 87077 eg ENGLAND to 87077 Try:WALES, SCOTLAND 4txt/Ì¼1.20 POBOXox36504W45WQ 16+"
</pre>
        You can detect yourself that the first and the last messages look like spam.
        But can Math do this enough well?
        An ordinary expert system can do this job probably very well.
        But they say, that Math can retrieve information from source data that you can't notice neither at first look nor after a week of thoroughly study it.
        So, this is the first simplest data-set to start. 
      </p>

      <p>This is about data mining (extracting information) from data without a classifying model (that trained on labeled train data).
        It's called "Unsupervised machine learning". If you look at <a href="#SCIKIT-USL">Unsupervised learning</a>, then you should find that it's not easy,
        it assumes that you should know Linear Algebra, Probability and Statistics, etc. 
      </p>
      
      <p>Any way, lets try Clustering, for example <a href="#SCIKIT-CLSTXT">Clustering text documents using k-means</a>.</p>
      
      <p>But first take a look at <a href="#SCIKIT-PREPARE">Preprocessing data</a>. That is we must convert text entries into numeric arrays (vectorization), etc.
        But before this we should prepare messages - lower case, leave only words, etc. See <a href="#KSDKAMESH99">Spam classifier</a> about data preparation.
        For example phrase "morefrmmob" stays unseparated by all methods.
        Sentence "ye gauti sehwag odi seri" becames "yes gauti sehwag odi series" by lemmatiziers (probably wrong fixing), although they did not fix "u know" to "you know".
      </p>
      
      <p>So, the first attempt is in <b>src/python/spam-detect/spam-clustering.py</b>. But results are different every time.
        And so does <a href="https://scikit-learn.org/stable/_downloads/ba68199eea858ec04949b2c6c65147e0/plot_document_clustering.py">https://scikit-learn.org/stable/_downloads/ba68199eea858ec04949b2c6c65147e0/plot_document_clustering.py</a>
        For SCILEARN example 1-st invocation:
<pre>
Homogeneity: 0.480
Completeness: 0.506
V-measure: 0.493
Adjusted Rand-Index: 0.486
Silhouette Coefficient: 0.005

Top terms per cluster:
Cluster 0: space cleveland cs com polygon sci higgins university freenet book
Cluster 1: graphics image thanks university file 3d files program format images
Cluster 2: god com people sandvik don jesus say article think christian
Cluster 3: com space access nasa digex posting article nntp host pat
</pre>
        For SCILEARN example 2-nd invocation:
<pre>
Homogeneity: 0.514
Completeness: 0.547
V-measure: 0.530
Adjusted Rand-Index: 0.478
Silhouette Coefficient: 0.008

Top terms per cluster:
Cluster 0: graphics image university thanks com ac 3d file files posting
Cluster 1: sandvik keith com sgi livesey kent apple morality caltech objective
Cluster 2: space nasa access digex henry gov pat shuttle toronto alaska
Cluster 3: god com people don just article jesus think like know
</pre>
        So, it's definitely more complex than previous article (Support Vector Machines), that gives the same result for any invocation.
        At first invocation category "space" seems to be divided into clusters #0 and #1, and "Atheism" and "Religion" seems to be merged into cluster #2.
        But why results are different? Maybe changing position of a word inside top terms means that neighboring words have the same frequency?
      </p>
      <p>
        The API says:
        <p><i>
        In practice, the k-means algorithm is very fast (one of the fastest clustering algorithms available), but it falls in local minima. That’s why it can be useful to restart it several times.
        </i></p>
        Using default settings (n_init - default=10 and max_iter - default=300) gives more stable results for SMS task, but it's more slowly:
<pre>
Homogeneity: 0.000
Completeness: 0.000
V-measure: 0.000
Adjusted Rand-Index: 0.003
Silhouette Coefficient: 0.005

Top 20 terms per cluster:
 Cluster 0: to the is in ok it my me and now for call your of on not ur that no at
 Cluster 1: you to are and me the have do call in your that how when can for what my it know
First 100 labels source-cluster:
0 - 0; 0 - 0; 1 - 0; 0 - 0; 0 - 0; 1 - 0; 0 - 0; 0 - 0; 1 - 1; 1 - 0; 0 - 0; 1 - 0; 1 - 1; 0 - 1; 0 - 0; 1 - 0; 0 - 0; 0 - 0; 0 - 0; 1 - 0; 0 - 1; 0 - 0; 0 - 0; 0 - 0; 0 - 1; 0 - 0; 0 - 0; 0 - 1; 0 - 1; 0 - 0; 0 - 1; 0 - 0; 0 - 1; 0 - 1; 1 - 1; 0 - 0; 0 - 1; 0 - 0; 0 - 0; 0 - 1; 0 - 0; 0 - 1; 1 - 1; 0 - 1; 0 - 1; 0 - 0; 0 - 1; 0 - 0; 0 - 0; 0 - 0; 0 - 1; 0 - 0; 0 - 0; 0 - 1; 1 - 0; 0 - 1; 1 - 0; 0 - 0; 0 - 1; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 1 - 1; 0 - 0; 1 - 0; 1 - 1; 0 - 0; 0 - 0; 0 - 1; 0 - 0; 0 - 1; 0 - 0; 0 - 1; 0 - 1; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 1; 0 - 0; 0 - 1; 0 - 0; 0 - 1; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 1; 0 - 0; 0 - 0; 1 - 1; 0 - 0; 1 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 
Accuracy = 68.12634601579325%
</pre>
        Sometimes cluster's labels are changed (inverted), so 32% means 68%.
      </p>
      <p><a href="#KSDKAMESH99">Spam classifier</a> gives 98.47% accuracy for SVM linear, 4457 train samples (5572 total), 1115 test samples (145 spam in them, 14 from them are wrong, i.e. Accuracy spam = 90.35%), PorterStemmer and sklearn.feature_extraction.text.CountVectorizer.
        If SVM (that is trained on these labeled data) can separate these samples so well, then it should be a Math method to train and separate the unlabeled ones enough well (70% isn't good).
        Indeed, for those processors the result is better (<b>src/python/spam-detect/spam-clustering1.py</b>):
<pre>
Homogeneity: 0.169
Completeness: 0.193
V-measure: 0.180
Adjusted Rand-Index: 0.367
Silhouette Coefficient: 0.090

Top 20 terms per cluster:
 Cluster 0: go get ur gt lt come ok day know love like got good time want send text need free txt
 Cluster 1: call free mobil claim min prize pleas contact urgent later award phone sorri ppm text custom number servic cash guarante

First 100 labels source-cluster:
0 - 0; 0 - 0; 1 - 0; 0 - 0; 0 - 0; 1 - 0; 0 - 0; 0 - 0; 1 - 1; 1 - 1; 0 - 0; 1 - 0; 1 - 0; 0 - 0; 0 - 0; 1 - 0; 0 - 0; 0 - 0; 0 - 0; 1 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 1 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 1 - 1; 0 - 0; 0 - 0; 0 - 1; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 1 - 0; 0 - 0; 1 - 1; 0 - 1; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 1 - 1; 0 - 0; 1 - 0; 1 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 1; 0 - 1; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 1; 0 - 1; 0 - 0; 0 - 0; 0 - 0; 0 - 1; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 1 - 1; 0 - 0; 1 - 0; 0 - 0; 0 - 0; 0 - 0; 0 - 0; 
Accuracy total = 87.86791098348887%
Spam total = 747 Accuracy spam = 45.64926372155288%
</pre>
        But accuracy for exactly SPAM messages (747 from 5572 total) is not good.
      </p>
      
      <p>References:</p>
      <ol>
        <li><a name="SCIKIT-PREPARE" href="https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing">https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing</a></li>
        <li><a name="SCIKIT-USL" href="https://scikit-learn.org/stable/unsupervised_learning.html">https://scikit-learn.org/stable/unsupervised_learning.html</a></li>
        <li><a name="SCIKIT-CLSTXT" href="https://scikit-learn.org/stable/auto_examples/text/plot_document_clustering.html#sphx-glr-auto-examples-text-plot-document-clustering-py">scikit-learn: Clustering text documents using k-means</a></li>
        <li><a name="KSDKAMESH99" href="https://github.com/ksdkamesh99/Spam-Classifier">https://github.com/ksdkamesh99/Spam-Classifier by Kota Sai Durga Kamesh (MIT License)</a></li>
        <li><a name="KAGGLE-SMS" href="https://www.kaggle.com/uciml/sms-spam-collection-dataset/download">SMS Spam Dataset created by UCI Machine Learning</a></li>
      </ol>
    </div>

    <footer class="blog-footer">
      Copyright &#169; 2021 <a href="https://demidenko05.github.io/beige-math/">Beigesoft™</a> All rights reserved.      
    </footer>

    </main>

  </body>

</html>
